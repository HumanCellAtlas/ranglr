---
title: "Ranglr walkthrough"
author: "Marion Shadbolt"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    keep_md: true
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Ranglr walkthrough}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Goals

This document aims to display some of the functionality of the `ranglr` R pacakge. The package aims to provide functions and tools to help primary wranglers wrangle their data and secondary wranglers review a dataset.

```{r setup}
library(ranglr)
library(magrittr)
```

# General Functionality

If you ever need help with a function the `?` is your friend.

```{r function_help}
?load_spreadsheet()
```


## Load a spreadsheet

This function loads a spreadsheet into R as a list of tibble objects. The list is named with the names of the tabs of the spreadsheet. This function discards the supplementary files tab if it is empty as well as the `Schemas` tab if it is present. It discards the top rows and retains the programmatic name as the names of the columns within each tab. The user just needs to provide the path to the spreadsheet they want to load.

For this walkthrough we are using a spreadsheet that has been submitted to the datastore and is (https://data.humancellatlas.org/explore/projects/f8aa201c-4ff1-45a4-890e-840d63459ca2)[currently in the browser]. 

```{r load_spreadsheet}
metadata_spreadsheet <- load_spreadsheet("../input/hca-metadata-spreadsheet-GSE95459-GSE114374-colon.xlsx")
names(metadata_spreadsheet)
```

## Summarise a spreadsheet

I think it would be good to see an overall summary of the spreadsheet. This function is still under development so any ideas for additional summary stats are most welcome. Current functionality:
* number of expected bundles
* number of accessions

```{r summarise_spreadsheet}
summary <- summarise_spreadsheet(metadata_spreadsheet)
```

## Build a dataframe with list of all column names found in each sheet

Returns a tibble with two columns, `sheet_name` and `col_name`.

```{r get_col_names}
get_col_names(metadata_spreadsheet)
```

From here you could filter column names to figure out where certain fields are found for example.

```{r filter_col_names}
get_col_names(metadata_spreadsheet) %>%
  dplyr::filter(stringr::str_detect(col_name, "biomaterial_id")) %>%
  dplyr::arrange(col_name)
```


## Get a list of all filenames in a spreadsheet

This is useful if you want to compare the files present in a spreadsheet to those present in the S3 bucket for a project.

```{r get_file_names}
files <- get_file_names(metadata_spreadsheet)
files[1:5]
```

## Build a linking data frame

Creates a dataframe that shows where there is a linking field between two tabs in a spreadsheet.

```{r linking_df}
linking_df <- build_linking_df(metadata_spreadsheet)
linking_df
```

## Validate link levels

For each entry in the `linking_field` column of the `linking_df` we need to check that each tab has consistent naming and the same number of levels are present in each. The function `validate_link_levels` does this and adds on columns to tell the user if each field passed the test.

```{r add_linking_validation}
linking_df <- validate_link_levels(linking_df)
linking_df
```

Then the df can be filtered to see if there are any fields that are invalid.

```{r non_matched_linking}
linking_df %>%
  dplyr::filter(! all_2_in_1 | ! all_1_in_2)
```

In this case all are okay.

## Secondary wrangler review process

<!-- ### Reconstruct experiment -->

<!-- #### Graph diagram -->

<!-- Currently thinking of how to implement this. -->

#### Confirm files uploaded to s3

Using the functions that query from s3 buckets require that the user already has access to the HCA DCP wrangler ec2 instance.

If you get the warning "Expected 4 pieces. Missing pieces filled with `NA` in 1 rows." this can be safely ignored.

```{r list_s3_files}
file_list_df <- list_s3_files(s3_url = "s3://org-humancellatlas-upload-staging/aaaaaaaa-bbbb-cccc-dddd-acf331bf0e8f/", 
                              user = "mshadbolt")

```

`check_uploaded_files` ensures all and only the files in the spreadsheet are in the s3 bucket and prints the results of the test to console.

```{r verify_files}
check_uploaded_files(files, file_list_df$file_name)
```

Example of using the `get_col_names` function if you don't remember which tab a certain field is in.

```{r get_col_names_example}
get_col_names(tibble_list = metadata_spreadsheet) %>%
  dplyr::filter(stringr::str_detect(col_name, "end_bias"))
```

Example of how to look at certain columns within a spreadsheet. You could decide you want to see all the ontology fields within the `Library preparation protocol` sheet

```{r get_ontology_fields_in_tab}
metadata_spreadsheet$`Library preparation protocol` %>% 
  dplyr::select(dplyr::contains("text"), dplyr::contains("ontology"))
```


#### Check ontologies

Get a list of all ontology fields in a spreadsheet, the `not_field` is what I call the programmatic name excluding the final `.` delimited segment..

```{r}
ontology_col_names <- get_col_names(metadata_spreadsheet) %>%
  dplyr::filter(stringr::str_detect(col_name, "ontology$")) %>%
  dplyr::rowwise() %>%
  dplyr::mutate(not_field = get_not_field_name(col_name)) %>%
  dplyr::ungroup() 

ontology_col_names
```

Look at a particular ontology field to view overall which ontologies were used and how many times they were used.

```{r tally_ontology_1}
tally_ontology(metadata_spreadsheet, "cell_suspension.genus_species",
               "Cell suspension")
```

```{r tally_ontology_2}
tally_ontology(metadata_spreadsheet, "specimen_from_organism.organ",
               "Specimen from organism")
```

Get tallies of all ontologies in a spreadsheet

```{r tally_all_ontologies}
all_ontologies <- get_ontologies(metadata_spreadsheet)
all_ontologies
```

#### Validate ontologies

Query an ontology in the hcao ols API

```{r query_ols}
api_response <- query_hca_ontology_term("EFO:0000606", "efo")
api_response
```

### Look up ontologies with ols api

Eventually I want to be able to check the ontologies in the spreadsheet using the API but this functionality is still under development

<!-- Leaving this here because I might be able to use simliar code and don't want
to forget about these functions-->
<!-- ```{r} -->
<!-- purrr::map2_dfr(.x = metadata_spreadsheet, -->
<!--                 .y = metadata_spreadsheet, -->
<!--                 .f = ~get_linking_fields(.x, .y)) %>% View() -->

<!-- purrr::map2_dfr(.x = metadata_spreadsheet, -->
<!--                 .y = names(metadata_spreadsheet), -->
<!--                 .f = colnames) -->
<!-- ``` -->


